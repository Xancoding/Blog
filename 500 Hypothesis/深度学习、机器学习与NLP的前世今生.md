---
doc_type: hypothesis-highlights
url: 'https://zhuanlan.zhihu.com/p/41583326'
---
# 深度学习、机器学习与NLP的前世今生
## Metadata
- Author: [zhuanlan.zhihu.com]()
- Title: 深度学习、机器学习与NLP的前世今生
- Reference: https://zhuanlan.zhihu.com/p/41583326
- Category: #source/article🗞
- Tags:
## Highlights
- 在深度学习在NLP领域火起来之前，最有代表性的一个研究、对每个人影响最大的工作就是Word2Vec，把一个字、一个词变成向量来表示，这是对我们影响非常大的工作。

- 这件事情的好处是什么？在之前我们以词为单位，一个词的表示方式几乎都是one hot， one hot序列有一个致命的缺点，你不能计算相似度，所有人算出来都是“0”，都是一样的，距离也都是一样的，因此它不能很好的表示词之间的关系。

- 第一，这个词如果有1万维的话，1万维本来存储它就是一个非常稀疏的矩阵、而且很浪费，我们就可以把它变得更小，因为我们的Word2Vec里面一般的向量都在 512以内。这个维度的向量相对1万维来说已经是比较低维的空间，它里面存的是各种的浮点数，这个浮点数看起来这三个向量好像每个都不一样，但是实际去计算，发现这三个向量之间的相似度非常高，一个是相似度可以判断它的相似性，另外是判断它们的距离。


- Tags:

- 威海、潍坊、枣庄这几个城市在空间上离得非常近，它们的数值也非常近。它对于我们实际工作的好处是增强了我们的泛化能力，这是一个很难做的事情。

- 第一，有更好的带语义的表示。

- 第二，有了这样的表示之后可以做语义的计算，包括山东-威海约等于广东-佛山，两个向量之间是约等于的，语义的东西不太好解释，但是人知道这是怎么回事，语义相近就是Word2Vec最大的帮助。

- 为什么叫深度学习？我们这只是一层，它在CNN里面尤其图像识别网络，大家都听过“大力出奇迹”，网络越深效果越好，因为它经过一层一层的学习，可以把每一层的特征进行浓缩。简单的像素没有任何的表义能力，到第一层浓缩之后它有一些点线的能力，再往上浓缩可能就有弧线的能力，再往上浓缩它越来越复杂，可以做到把一个像素这个没有意义的东西变成有意义的东西，可以它可以看成是一层层的过滤，选出最好的特征结果，这是卷积的原理。卷积不仅仅在图像里，在文本里用得也非常好。


- Tags:

- 3、many to one。输入的是一个序列，文字等都是这样一个序列，这个序列输出之后做文本分类、情感分析，它最终都给出来这样一个结果，它们都属于“多到一”的过程。

- 2、one to many。图像描述。

- 一个图像进来了，它告诉我图像上有一个狗、一个猫站在车旁边，这就是一个图像描述的过程，它可以把图像变成很多输出，这就是one to many的问题。

- 、one to one。图像分类

- 传统的机器学习，需要构造特征，不同领域定制化程度很高，这个模型A领域用了，B领域几乎要从头再做一遍，没有办法把其他的特征迁移过来很好的使用。某些领域效果很好，某些领域另外一个算法很好，传统机器学习把各种各样的方式做以融合来提升效果。

